#!/usr/bin/env python3
"""
Test script to verify that ALL messages now go through the LLM
No more fast replies or fallback mechanisms should exist
"""

import asyncio
import sys
import os

# Add the project root to Python path
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from agents.query_agent import query_agent

async def test_no_fast_replies():
    print("ğŸ§ª Testing That ALL Messages Go Through LLM")
    print("=" * 60)
    
    test_messages = [
        {
            "message": "Ø§Ù„Ø³Ù„Ø§Ù… Ø¹Ù„ÙŠÙƒÙ…",
            "language": "ar",
            "description": "Greeting (previously had fast reply)"
        },
        {
            "message": "Hello",
            "language": "en", 
            "description": "English greeting (previously had fast reply)"
        },
        {
            "message": "Ø´ÙƒØ±Ø§Ù‹ Ù„ÙƒÙ…",
            "language": "ar",
            "description": "Thank you message (suggestion type)"
        },
        {
            "message": "Ù…Ø§ Ù‡ÙŠ Ø§Ù„Ø¹Ù„Ø§Ù…Ø§Øª Ø§Ù„ØªØ¬Ø§Ø±ÙŠØ© Ø§Ù„Ù…ØªØ§Ø­Ø©ØŸ",
            "language": "ar",
            "description": "Vague brands question (should ask directly: 'Ø£ÙŠ Ù…Ø¯ÙŠÙ†Ø©ØŸ')"
        },
        {
            "message": "What products do you have?",
            "language": "en",
            "description": "Vague products question (should ask directly: 'Which city?')"
        }
    ]
    
    for i, test in enumerate(test_messages, 1):
        print(f"\n{i}. Testing: '{test['message']}'")
        print(f"   Language: {test['language']}")
        print(f"   Context: {test['description']}")
        print(f"   {'='*40}")
        
        try:
            # This should ALL go through LLM now
            response = await query_agent.process_query(
                user_message=test['message'],
                conversation_history=[],
                user_language=test['language']
            )
            
            print(f"   ğŸ¤– LLM Response: {response[:100]}...")
            
            # Check if it's a direct question as expected
            if test['message'] in ["Ù…Ø§ Ù‡ÙŠ Ø§Ù„Ø¹Ù„Ø§Ù…Ø§Øª Ø§Ù„ØªØ¬Ø§Ø±ÙŠØ© Ø§Ù„Ù…ØªØ§Ø­Ø©ØŸ", "What products do you have?"]:
                if any(word in response.lower() for word in ["Ø£ÙŠ Ù…Ø¯ÙŠÙ†Ø©", "which city", "Ù…Ø¯ÙŠÙ†Ø©"]):
                    print(f"   âœ… Direct question style detected!")
                else:
                    print(f"   âš ï¸  Response style: {response[:50]}...")
            
        except Exception as e:
            print(f"   âŒ Error: {str(e)}")
        
        print(f"   {'-'*40}")

async def test_direct_questioning():
    print(f"\nğŸ¯ Testing Direct Questioning Style")
    print("=" * 60)
    
    # Test conversation flow to see direct questioning
    conversation = []
    
    # First message - vague question
    print(f"\n1. User: 'Ù…Ø§ Ù‡ÙŠ Ø§Ù„Ø¹Ù„Ø§Ù…Ø§Øª Ø§Ù„ØªØ¬Ø§Ø±ÙŠØ©ØŸ'")
    response1 = await query_agent.process_query(
        user_message="Ù…Ø§ Ù‡ÙŠ Ø§Ù„Ø¹Ù„Ø§Ù…Ø§Øª Ø§Ù„ØªØ¬Ø§Ø±ÙŠØ©ØŸ",
        conversation_history=conversation,
        user_language="ar"
    )
    print(f"   Bot: {response1}")
    
    # Add to conversation history
    conversation.extend([
        {"role": "user", "content": "Ù…Ø§ Ù‡ÙŠ Ø§Ù„Ø¹Ù„Ø§Ù…Ø§Øª Ø§Ù„ØªØ¬Ø§Ø±ÙŠØ©ØŸ"},
        {"role": "assistant", "content": response1}
    ])
    
    # Second message - answer with city
    print(f"\n2. User: 'Ø§Ù„Ø±ÙŠØ§Ø¶'")
    response2 = await query_agent.process_query(
        user_message="Ø§Ù„Ø±ÙŠØ§Ø¶",
        conversation_history=conversation,
        user_language="ar"
    )
    print(f"   Bot: {response2[:200]}...")

if __name__ == "__main__":
    print("ğŸ”§ Testing Enhanced Query Agent - No Fast Replies")
    print("All messages should now go through the LLM")
    print("=" * 60)
    
    asyncio.run(test_no_fast_replies())
    asyncio.run(test_direct_questioning())
    
    print(f"\nâœ… Test Complete!")
    print("If you see LLM responses for all messages above, the fast reply removal was successful!") 